{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EmotionsRecognition.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "CjWvnaQUrZmD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Emotion classification using the RAVDESS dataset"
      ]
    },
    {
      "metadata": {
        "id": "ldtHMhuLrewK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) is licensed under CC BY-NA-SC 4.0. and can be downloaded free of charge at https://zenodo.org/record/1188976.\n",
        "\n",
        "***Construction and Validation***\n",
        "\n",
        "Construction and validation of the RAVDESS is described in our paper: Livingstone SR, Russo FA (2018) The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English. PLoS ONE 13(5): e0196391. https://doi.org/10.1371/journal.pone.0196391.\n",
        "\n",
        "The RAVDESS contains 7356 files. Each file was rated 10 times on emotional validity, intensity, and genuineness. Ratings were provided by 247 individuals who were characteristic of untrained adult research participants from North America. A further set of 72 participants provided test-retest data. High levels of emotional validity, interrater reliability, and test-retest intrarater reliability were reported. Validation data is open-access, and can be downloaded along with our paper from PLOS ONE.\n",
        "\n",
        "***Description***\n",
        "\n",
        "The dataset contains the complete set of 7356 RAVDESS files (total size: 24.8 GB). Each of the 24 actors consists of three modality formats: Audio-only (16bit, 48kHz .wav), Audio-Video (720p H.264, AAC 48kHz, .mp4), and Video-only (no sound).  Note, there are no song files for Actor_18.\n",
        "\n",
        "***Data***\n",
        "\n",
        "For this notebook, Audio-Only files have been used (2452 files).\n",
        "\n",
        "***License information***\n",
        "\n",
        "The RAVDESS is released under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License, CC BY-NA-SC 4.0\n",
        "\n",
        "***File naming convention***\n",
        "\n",
        "Each of the 7356 RAVDESS files has a unique filename. The filename consists of a 7-part numerical identifier (e.g., 02-01-06-01-02-01-12.mp4). These identifiers define the stimulus characteristics:\n",
        "\n",
        "***Filename identifiers***\n",
        "\n",
        "- Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "- Vocal channel (01 = speech, 02 = song).\n",
        "- Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "- Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the ‘neutral’ emotion.\n",
        "- Statement (01 = “Kids are talking by the door”, 02 = “Dogs are sitting by the door”).\n",
        "- Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "- Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "\n",
        "Filename example: 02-01-06-01-02-01-12.mp4 \n",
        "\n",
        "- Video-only (02)\n",
        "- Speech (01)\n",
        "- Fearful (06)\n",
        "- Normal intensity (01)\n",
        "- Statement “dogs” (02)\n",
        "- 1st Repetition (01)\n",
        "- 12th Actor (12)\n",
        "- Female, as the actor ID number is even."
      ]
    },
    {
      "metadata": {
        "id": "JDNbxj45rkvB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "We are using Colab, a Google Cloud environment for jupyter, so we need to import our files from Google Drive and then install LibROSA, a python package for music and audio analysis.\n",
        "\n",
        "After the import, we will plot the signal of the first file."
      ]
    },
    {
      "metadata": {
        "id": "N-o2JI49WBAe",
        "colab_type": "code",
        "outputId": "947a9b23-8f4b-448e-bec4-c299f5c66be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: "***",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EgFwaDhMbJVm",
        "colab_type": "code",
        "outputId": "18885f04-f87a-48fa-bd9d-6926face78d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install librosa"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (2.1.6)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.20.1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.13.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (4.3.0)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa) (1.11.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.2.1)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa) (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa) (0.26.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rxI4xzngdS-e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "from librosa import display\n",
        "\n",
        "data, sampling_rate = librosa.load('/content/drive/My Drive/Ravdess/03-01-01-01-01-01-01.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WgaSHtCIdtX2",
        "colab_type": "code",
        "outputId": "11d0e432-5188-46b2-97d3-97093342449b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "% pylab inline\n",
        "import os\n",
        "import pandas as pd\n",
        "import glob \n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "librosa.display.waveplot(data, sr=sampling_rate)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['display']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PolyCollection at 0x7f26b6d392b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAEGCAYAAABxSsNVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f26b7d32a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vCtNuVWlr5jL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load all files\n",
        "\n",
        "We will create our numpy array extracting Mel-frequency cepstral coefficients (MFCCs), while the classes to predict will be extracted from the name of the file (see the introductory section of this notebook to see the naming convention of the files of this dataset)."
      ]
    },
    {
      "metadata": {
        "id": "AKvuF--gd6F-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/Ravdess'\n",
        "lst = []\n",
        "\n",
        "for subdir, dirs, files in os.walk(path):\n",
        "  for file in files:\n",
        "      try:\n",
        "        #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
        "        X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "        file = file[6:8]\n",
        "        arr = mfccs, file\n",
        "        lst.append(arr)\n",
        "      # If the file is not valid, skip it\n",
        "      except ValueError:\n",
        "        continue       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kLSggnF7kKY1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
        "X, y = zip(*lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VzvBRTJIlIE9",
        "colab_type": "code",
        "outputId": "3f7f2167-b3bc-446c-d5ce-e18d677b8c12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2452, 40), (2452,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "Agw-3KN1sDhh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Decision Tree Classifier\n",
        "\n",
        "To make a first attempt in accomplishing this classification task I chose a decision tree:"
      ]
    },
    {
      "metadata": {
        "id": "Q-Xgb5NslTBO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UshLOC1ClWL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_BnCR52nlXw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dtree = DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qWyTownblZM0",
        "colab_type": "code",
        "outputId": "f0657be4-d90f-44ad-ab54-f0993feb81d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "dtree.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "            max_features=None, max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
              "            splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "HEuw6TUQlr7C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = dtree.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_1v0i0V7sMw7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's go with our classification report.\n",
        "\n",
        "Before we start, a quick reminder of the classes we are trying to predict:\n",
        "\n",
        "emotions = {\n",
        "    \"neutral\": \"01\",\n",
        "    \"calm\": \"02\",\n",
        "    \"happy\": \"03\",\n",
        "    \"sad\": \"04\",\n",
        "    \"angry\": \"05\", \n",
        "    \"fearful\": \"06\", \n",
        "    \"disgust\": \"07\", \n",
        "    \"surprised\": \"08\"\n",
        "}"
      ]
    },
    {
      "metadata": {
        "id": "c4kNSYkAleIv",
        "colab_type": "code",
        "outputId": "9cc97330-af2e-4473-f3a2-df04a6e06797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          01       0.45      0.45      0.45        66\n",
            "          02       0.54      0.57      0.55       126\n",
            "          03       0.50      0.39      0.44       120\n",
            "          04       0.39      0.46      0.42       121\n",
            "          05       0.61      0.63      0.62       118\n",
            "          06       0.43      0.39      0.41       131\n",
            "          07       0.31      0.30      0.31        66\n",
            "          08       0.34      0.35      0.35        62\n",
            "\n",
            "   micro avg       0.46      0.46      0.46       810\n",
            "   macro avg       0.44      0.44      0.44       810\n",
            "weighted avg       0.46      0.46      0.46       810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x2YH_Ttaw2Am",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Being a multiclass problem (8 classes to predict) and with a little dataset, the result is not that bad.\n",
        "\n",
        "In particular, we have a starting point for precision/recall tradeoff for the classes Calm (02) and Angry (05)"
      ]
    },
    {
      "metadata": {
        "id": "lCVgjLj-gwE2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ]
    },
    {
      "metadata": {
        "id": "jfaTxzZ1w__y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this second approach, I switched to a random forest classifier and I made a gridsearch to make some hyperparameters tuning.\n",
        "\n",
        "The gridsearch is not shown in the code below otherwise the notebook will require too much time to run."
      ]
    },
    {
      "metadata": {
        "id": "wcov_DCXgs7v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3eo0ljqzg-KM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rforest = RandomForestClassifier(criterion=\"gini\", max_depth=10, max_features=\"log2\", \n",
        "                                 max_leaf_nodes = 100, min_samples_leaf = 3, min_samples_split = 20, \n",
        "                                 n_estimators= 22000, random_state= 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tg45qSOfg-26",
        "colab_type": "code",
        "outputId": "d81a228a-646a-44b7-fd9a-70d24672903e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "rforest.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=10, max_features='log2', max_leaf_nodes=100,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=3, min_samples_split=20,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=22000, n_jobs=None,\n",
              "            oob_score=False, random_state=5, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "aM8KU3qxhGBM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = rforest.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "296FW5sBdanI",
        "colab_type": "code",
        "outputId": "b7453867-2d7f-4825-80e7-cee96faf6222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          01       0.92      0.33      0.49        66\n",
            "          02       0.60      0.87      0.71       126\n",
            "          03       0.76      0.59      0.67       120\n",
            "          04       0.46      0.53      0.49       121\n",
            "          05       0.68      0.81      0.74       118\n",
            "          06       0.67      0.60      0.63       131\n",
            "          07       0.57      0.39      0.46        66\n",
            "          08       0.53      0.60      0.56        62\n",
            "\n",
            "   micro avg       0.62      0.62      0.62       810\n",
            "   macro avg       0.65      0.59      0.59       810\n",
            "weighted avg       0.64      0.62      0.61       810\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ksfovJ2RxLTS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have an improvement: what we see is that the classes \"Happy\" (03), Angry\" (05) and \"Neutral\" (01) are the easiest to predict for this model."
      ]
    },
    {
      "metadata": {
        "id": "t9eqMHV3S8i6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural network"
      ]
    },
    {
      "metadata": {
        "id": "G-QscoyMxQtn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are going to do 2 actions: \n",
        "\n",
        "1) Expand the dimensions of our array, adding a third one (this is necessary for the Neural Network);\n",
        "\n",
        "2) Build our network."
      ]
    },
    {
      "metadata": {
        "id": "W4i187-Pe-w5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_traincnn = np.expand_dims(X_train, axis=2)\n",
        "x_testcnn = np.expand_dims(X_test, axis=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnvoCRX1gQCh",
        "colab_type": "code",
        "outputId": "5ae2549d-557f-4ec6-ed40-70a71db69f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_traincnn.shape, x_testcnn.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1642, 40, 1), (810, 40, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "HZOGIpuefCd3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "'''\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(256, 5,padding='same',\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5,padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 5,padding='same',))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv1D(128, 5,padding='same',\n",
        "                 input_shape=(40,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.rmsprop(lr=0.000007, rho=0.9, epsilon=None, decay=0.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LphftMIZzUvz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With *model.summary* we can see a recap of what we have build:"
      ]
    },
    {
      "metadata": {
        "id": "pIWPB4Zgfic7",
        "colab_type": "code",
        "outputId": "08ae0598-40e4-4d6e-dc67-b580fa12aeeb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_76 (Conv1D)           (None, 40, 128)           768       \n",
            "_________________________________________________________________\n",
            "activation_146 (Activation)  (None, 40, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten_67 (Flatten)         (None, 5120)              0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 10)                51210     \n",
            "_________________________________________________________________\n",
            "activation_147 (Activation)  (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 51,978\n",
            "Trainable params: 51,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5qQSBeBhzcLu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can compile and fit our model:"
      ]
    },
    {
      "metadata": {
        "id": "iNI1znbsfpTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ktdF-nJKfq6F",
        "colab_type": "code",
        "outputId": "4eef1732-0ea4-4198-c139-4a621dd8c723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17034
        }
      },
      "cell_type": "code",
      "source": [
        "cnnhistory=model.fit(x_traincnn, y_train, batch_size=16, epochs=500, validation_data=(x_testcnn, y_test))"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1642 samples, validate on 810 samples\n",
            "Epoch 1/500\n",
            "1642/1642 [==============================] - 3s 2ms/step - loss: 13.3870 - acc: 0.0792 - val_loss: 11.7579 - val_acc: 0.0765\n",
            "Epoch 2/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 8.6783 - acc: 0.1060 - val_loss: 6.0406 - val_acc: 0.1519\n",
            "Epoch 3/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 4.3929 - acc: 0.2022 - val_loss: 3.5089 - val_acc: 0.2210\n",
            "Epoch 4/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 2.9164 - acc: 0.2107 - val_loss: 2.6087 - val_acc: 0.2099\n",
            "Epoch 5/500\n",
            "1642/1642 [==============================] - 1s 309us/step - loss: 2.3660 - acc: 0.2113 - val_loss: 2.1772 - val_acc: 0.2272\n",
            "Epoch 6/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 2.0650 - acc: 0.2278 - val_loss: 2.0145 - val_acc: 0.2519\n",
            "Epoch 7/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 1.9771 - acc: 0.2412 - val_loss: 1.9589 - val_acc: 0.2568\n",
            "Epoch 8/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 1.9291 - acc: 0.2600 - val_loss: 1.9131 - val_acc: 0.2593\n",
            "Epoch 9/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 1.8898 - acc: 0.2795 - val_loss: 1.8896 - val_acc: 0.2790\n",
            "Epoch 10/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 1.8526 - acc: 0.3021 - val_loss: 1.8461 - val_acc: 0.2852\n",
            "Epoch 11/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 1.8168 - acc: 0.3112 - val_loss: 1.8354 - val_acc: 0.2877\n",
            "Epoch 12/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 1.7888 - acc: 0.3167 - val_loss: 1.7921 - val_acc: 0.3136\n",
            "Epoch 13/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 1.7615 - acc: 0.3283 - val_loss: 1.7678 - val_acc: 0.3198\n",
            "Epoch 14/500\n",
            "1642/1642 [==============================] - 0s 304us/step - loss: 1.7389 - acc: 0.3386 - val_loss: 1.7454 - val_acc: 0.3272\n",
            "Epoch 15/500\n",
            "1642/1642 [==============================] - 0s 298us/step - loss: 1.7146 - acc: 0.3587 - val_loss: 1.7301 - val_acc: 0.3259\n",
            "Epoch 16/500\n",
            "1642/1642 [==============================] - 1s 306us/step - loss: 1.6946 - acc: 0.3648 - val_loss: 1.7128 - val_acc: 0.3198\n",
            "Epoch 17/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 1.6750 - acc: 0.3678 - val_loss: 1.6994 - val_acc: 0.3531\n",
            "Epoch 18/500\n",
            "1642/1642 [==============================] - 1s 315us/step - loss: 1.6574 - acc: 0.3837 - val_loss: 1.6742 - val_acc: 0.3593\n",
            "Epoch 19/500\n",
            "1642/1642 [==============================] - 1s 310us/step - loss: 1.6392 - acc: 0.3922 - val_loss: 1.6625 - val_acc: 0.3506\n",
            "Epoch 20/500\n",
            "1642/1642 [==============================] - 1s 306us/step - loss: 1.6219 - acc: 0.4056 - val_loss: 1.6469 - val_acc: 0.3753\n",
            "Epoch 21/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 1.6082 - acc: 0.4050 - val_loss: 1.6312 - val_acc: 0.3901\n",
            "Epoch 22/500\n",
            "1642/1642 [==============================] - 1s 305us/step - loss: 1.5915 - acc: 0.4184 - val_loss: 1.6227 - val_acc: 0.3901\n",
            "Epoch 23/500\n",
            "1642/1642 [==============================] - 0s 301us/step - loss: 1.5781 - acc: 0.4172 - val_loss: 1.6124 - val_acc: 0.3951\n",
            "Epoch 24/500\n",
            "1642/1642 [==============================] - 0s 300us/step - loss: 1.5654 - acc: 0.4318 - val_loss: 1.5968 - val_acc: 0.4222\n",
            "Epoch 25/500\n",
            "1642/1642 [==============================] - 0s 301us/step - loss: 1.5497 - acc: 0.4543 - val_loss: 1.5954 - val_acc: 0.4000\n",
            "Epoch 26/500\n",
            "1642/1642 [==============================] - 0s 301us/step - loss: 1.5409 - acc: 0.4440 - val_loss: 1.5746 - val_acc: 0.4247\n",
            "Epoch 27/500\n",
            "1642/1642 [==============================] - 0s 293us/step - loss: 1.5261 - acc: 0.4568 - val_loss: 1.5731 - val_acc: 0.4086\n",
            "Epoch 28/500\n",
            "1642/1642 [==============================] - 0s 297us/step - loss: 1.5136 - acc: 0.4604 - val_loss: 1.5599 - val_acc: 0.4284\n",
            "Epoch 29/500\n",
            "1642/1642 [==============================] - 0s 295us/step - loss: 1.5042 - acc: 0.4653 - val_loss: 1.5506 - val_acc: 0.4346\n",
            "Epoch 30/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.4914 - acc: 0.4677 - val_loss: 1.5436 - val_acc: 0.4333\n",
            "Epoch 31/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.4844 - acc: 0.4769 - val_loss: 1.5359 - val_acc: 0.4370\n",
            "Epoch 32/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.4713 - acc: 0.4781 - val_loss: 1.5227 - val_acc: 0.4580\n",
            "Epoch 33/500\n",
            "1642/1642 [==============================] - 1s 308us/step - loss: 1.4621 - acc: 0.4793 - val_loss: 1.5246 - val_acc: 0.4469\n",
            "Epoch 34/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.4571 - acc: 0.4939 - val_loss: 1.5074 - val_acc: 0.4617\n",
            "Epoch 35/500\n",
            "1642/1642 [==============================] - 0s 297us/step - loss: 1.4468 - acc: 0.5018 - val_loss: 1.5028 - val_acc: 0.4531\n",
            "Epoch 36/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 1.4392 - acc: 0.4988 - val_loss: 1.4927 - val_acc: 0.4691\n",
            "Epoch 37/500\n",
            "1642/1642 [==============================] - 0s 298us/step - loss: 1.4324 - acc: 0.4976 - val_loss: 1.4877 - val_acc: 0.4679\n",
            "Epoch 38/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.4220 - acc: 0.5030 - val_loss: 1.4783 - val_acc: 0.4827\n",
            "Epoch 39/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.4127 - acc: 0.5085 - val_loss: 1.4804 - val_acc: 0.4753\n",
            "Epoch 40/500\n",
            "1642/1642 [==============================] - 1s 306us/step - loss: 1.4066 - acc: 0.5134 - val_loss: 1.4692 - val_acc: 0.4889\n",
            "Epoch 41/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 1.3989 - acc: 0.5158 - val_loss: 1.4661 - val_acc: 0.4790\n",
            "Epoch 42/500\n",
            "1642/1642 [==============================] - 1s 314us/step - loss: 1.3922 - acc: 0.5146 - val_loss: 1.4560 - val_acc: 0.4716\n",
            "Epoch 43/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 1.3821 - acc: 0.5195 - val_loss: 1.4580 - val_acc: 0.4926\n",
            "Epoch 44/500\n",
            "1642/1642 [==============================] - 1s 314us/step - loss: 1.3789 - acc: 0.5225 - val_loss: 1.4447 - val_acc: 0.4864\n",
            "Epoch 45/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 1.3725 - acc: 0.5225 - val_loss: 1.4360 - val_acc: 0.5086\n",
            "Epoch 46/500\n",
            "1642/1642 [==============================] - 1s 314us/step - loss: 1.3632 - acc: 0.5323 - val_loss: 1.4340 - val_acc: 0.5000\n",
            "Epoch 47/500\n",
            "1642/1642 [==============================] - 0s 301us/step - loss: 1.3580 - acc: 0.5335 - val_loss: 1.4269 - val_acc: 0.4988\n",
            "Epoch 48/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 1.3501 - acc: 0.5335 - val_loss: 1.4224 - val_acc: 0.5247\n",
            "Epoch 49/500\n",
            "1642/1642 [==============================] - 1s 309us/step - loss: 1.3455 - acc: 0.5317 - val_loss: 1.4200 - val_acc: 0.5272\n",
            "Epoch 50/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 1.3415 - acc: 0.5353 - val_loss: 1.4101 - val_acc: 0.5235\n",
            "Epoch 51/500\n",
            "1642/1642 [==============================] - 1s 305us/step - loss: 1.3346 - acc: 0.5353 - val_loss: 1.4064 - val_acc: 0.5160\n",
            "Epoch 52/500\n",
            "1642/1642 [==============================] - 1s 313us/step - loss: 1.3280 - acc: 0.5438 - val_loss: 1.4054 - val_acc: 0.5074\n",
            "Epoch 53/500\n",
            "1642/1642 [==============================] - 1s 306us/step - loss: 1.3220 - acc: 0.5463 - val_loss: 1.3967 - val_acc: 0.5210\n",
            "Epoch 54/500\n",
            "1642/1642 [==============================] - 0s 300us/step - loss: 1.3174 - acc: 0.5402 - val_loss: 1.4000 - val_acc: 0.5099\n",
            "Epoch 55/500\n",
            "1642/1642 [==============================] - 0s 302us/step - loss: 1.3140 - acc: 0.5475 - val_loss: 1.3892 - val_acc: 0.5296\n",
            "Epoch 56/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 1.3038 - acc: 0.5481 - val_loss: 1.3934 - val_acc: 0.5247\n",
            "Epoch 57/500\n",
            "1642/1642 [==============================] - 1s 313us/step - loss: 1.3035 - acc: 0.5536 - val_loss: 1.3815 - val_acc: 0.5346\n",
            "Epoch 58/500\n",
            "1642/1642 [==============================] - 1s 314us/step - loss: 1.2974 - acc: 0.5542 - val_loss: 1.3773 - val_acc: 0.5309\n",
            "Epoch 59/500\n",
            "1642/1642 [==============================] - 0s 296us/step - loss: 1.2908 - acc: 0.5560 - val_loss: 1.3742 - val_acc: 0.5309\n",
            "Epoch 60/500\n",
            "1642/1642 [==============================] - 1s 307us/step - loss: 1.2863 - acc: 0.5524 - val_loss: 1.3718 - val_acc: 0.5395\n",
            "Epoch 61/500\n",
            "1642/1642 [==============================] - 0s 295us/step - loss: 1.2793 - acc: 0.5566 - val_loss: 1.3727 - val_acc: 0.5383\n",
            "Epoch 62/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.2758 - acc: 0.5609 - val_loss: 1.3683 - val_acc: 0.5395\n",
            "Epoch 63/500\n",
            "1642/1642 [==============================] - 0s 289us/step - loss: 1.2722 - acc: 0.5585 - val_loss: 1.3613 - val_acc: 0.5370\n",
            "Epoch 64/500\n",
            "1642/1642 [==============================] - 0s 298us/step - loss: 1.2677 - acc: 0.5603 - val_loss: 1.3597 - val_acc: 0.5309\n",
            "Epoch 65/500\n",
            "1642/1642 [==============================] - 0s 298us/step - loss: 1.2640 - acc: 0.5627 - val_loss: 1.3523 - val_acc: 0.5543\n",
            "Epoch 66/500\n",
            "1642/1642 [==============================] - 0s 295us/step - loss: 1.2587 - acc: 0.5670 - val_loss: 1.3501 - val_acc: 0.5432\n",
            "Epoch 67/500\n",
            "1642/1642 [==============================] - 0s 304us/step - loss: 1.2553 - acc: 0.5597 - val_loss: 1.3462 - val_acc: 0.5519\n",
            "Epoch 68/500\n",
            "1642/1642 [==============================] - 0s 304us/step - loss: 1.2507 - acc: 0.5798 - val_loss: 1.3442 - val_acc: 0.5457\n",
            "Epoch 69/500\n",
            "1642/1642 [==============================] - 0s 299us/step - loss: 1.2454 - acc: 0.5749 - val_loss: 1.3382 - val_acc: 0.5593\n",
            "Epoch 70/500\n",
            "1642/1642 [==============================] - 0s 304us/step - loss: 1.2417 - acc: 0.5725 - val_loss: 1.3377 - val_acc: 0.5580\n",
            "Epoch 71/500\n",
            "1642/1642 [==============================] - 0s 299us/step - loss: 1.2373 - acc: 0.5664 - val_loss: 1.3340 - val_acc: 0.5556\n",
            "Epoch 72/500\n",
            "1642/1642 [==============================] - 0s 304us/step - loss: 1.2324 - acc: 0.5713 - val_loss: 1.3410 - val_acc: 0.5370\n",
            "Epoch 73/500\n",
            "1642/1642 [==============================] - 1s 305us/step - loss: 1.2295 - acc: 0.5786 - val_loss: 1.3340 - val_acc: 0.5469\n",
            "Epoch 74/500\n",
            "1642/1642 [==============================] - 0s 302us/step - loss: 1.2274 - acc: 0.5853 - val_loss: 1.3286 - val_acc: 0.5568\n",
            "Epoch 75/500\n",
            "1642/1642 [==============================] - 1s 310us/step - loss: 1.2215 - acc: 0.5828 - val_loss: 1.3260 - val_acc: 0.5617\n",
            "Epoch 76/500\n",
            "1642/1642 [==============================] - 1s 312us/step - loss: 1.2184 - acc: 0.5761 - val_loss: 1.3229 - val_acc: 0.5617\n",
            "Epoch 77/500\n",
            "1642/1642 [==============================] - 1s 366us/step - loss: 1.2155 - acc: 0.5755 - val_loss: 1.3213 - val_acc: 0.5469\n",
            "Epoch 78/500\n",
            "1642/1642 [==============================] - 1s 360us/step - loss: 1.2115 - acc: 0.5859 - val_loss: 1.3160 - val_acc: 0.5617\n",
            "Epoch 79/500\n",
            "1642/1642 [==============================] - 1s 360us/step - loss: 1.2069 - acc: 0.5895 - val_loss: 1.3141 - val_acc: 0.5605\n",
            "Epoch 80/500\n",
            "1642/1642 [==============================] - 1s 366us/step - loss: 1.2050 - acc: 0.5865 - val_loss: 1.3064 - val_acc: 0.5716\n",
            "Epoch 81/500\n",
            "1642/1642 [==============================] - 1s 371us/step - loss: 1.2004 - acc: 0.5895 - val_loss: 1.3105 - val_acc: 0.5667\n",
            "Epoch 82/500\n",
            "1642/1642 [==============================] - 1s 358us/step - loss: 1.1994 - acc: 0.5822 - val_loss: 1.3032 - val_acc: 0.5741\n",
            "Epoch 83/500\n",
            "1642/1642 [==============================] - 1s 359us/step - loss: 1.1930 - acc: 0.5926 - val_loss: 1.3054 - val_acc: 0.5802\n",
            "Epoch 84/500\n",
            "1642/1642 [==============================] - 1s 360us/step - loss: 1.1909 - acc: 0.5932 - val_loss: 1.3050 - val_acc: 0.5704\n",
            "Epoch 85/500\n",
            "1642/1642 [==============================] - 1s 359us/step - loss: 1.1865 - acc: 0.5816 - val_loss: 1.2997 - val_acc: 0.5716\n",
            "Epoch 86/500\n",
            "1642/1642 [==============================] - 1s 364us/step - loss: 1.1855 - acc: 0.5950 - val_loss: 1.2956 - val_acc: 0.5802\n",
            "Epoch 87/500\n",
            "1642/1642 [==============================] - 1s 369us/step - loss: 1.1799 - acc: 0.5871 - val_loss: 1.2928 - val_acc: 0.5765\n",
            "Epoch 88/500\n",
            "1642/1642 [==============================] - 1s 357us/step - loss: 1.1767 - acc: 0.6011 - val_loss: 1.2943 - val_acc: 0.5605\n",
            "Epoch 89/500\n",
            "1642/1642 [==============================] - 1s 359us/step - loss: 1.1758 - acc: 0.5926 - val_loss: 1.2863 - val_acc: 0.5778\n",
            "Epoch 90/500\n",
            "1642/1642 [==============================] - 1s 362us/step - loss: 1.1700 - acc: 0.6017 - val_loss: 1.2825 - val_acc: 0.5852\n",
            "Epoch 91/500\n",
            "1642/1642 [==============================] - 1s 358us/step - loss: 1.1694 - acc: 0.5962 - val_loss: 1.2850 - val_acc: 0.5691\n",
            "Epoch 92/500\n",
            "1642/1642 [==============================] - 1s 359us/step - loss: 1.1642 - acc: 0.5999 - val_loss: 1.2809 - val_acc: 0.5889\n",
            "Epoch 93/500\n",
            "1642/1642 [==============================] - 1s 362us/step - loss: 1.1630 - acc: 0.5987 - val_loss: 1.2790 - val_acc: 0.5815\n",
            "Epoch 94/500\n",
            "1642/1642 [==============================] - 1s 337us/step - loss: 1.1596 - acc: 0.5974 - val_loss: 1.2808 - val_acc: 0.5704\n",
            "Epoch 95/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.1579 - acc: 0.5999 - val_loss: 1.2767 - val_acc: 0.5778\n",
            "Epoch 96/500\n",
            "1642/1642 [==============================] - 0s 301us/step - loss: 1.1541 - acc: 0.6029 - val_loss: 1.2719 - val_acc: 0.5914\n",
            "Epoch 97/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 1.1524 - acc: 0.5981 - val_loss: 1.2682 - val_acc: 0.5815\n",
            "Epoch 98/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 1.1484 - acc: 0.6041 - val_loss: 1.2744 - val_acc: 0.5716\n",
            "Epoch 99/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 1.1450 - acc: 0.6078 - val_loss: 1.2678 - val_acc: 0.5901\n",
            "Epoch 100/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 1.1425 - acc: 0.6084 - val_loss: 1.2665 - val_acc: 0.5926\n",
            "Epoch 101/500\n",
            "1642/1642 [==============================] - 1s 314us/step - loss: 1.1388 - acc: 0.6218 - val_loss: 1.2711 - val_acc: 0.5914\n",
            "Epoch 102/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 1.1384 - acc: 0.6084 - val_loss: 1.2623 - val_acc: 0.5852\n",
            "Epoch 103/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 1.1357 - acc: 0.6017 - val_loss: 1.2588 - val_acc: 0.5975\n",
            "Epoch 104/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 1.1329 - acc: 0.6121 - val_loss: 1.2588 - val_acc: 0.5988\n",
            "Epoch 105/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 1.1311 - acc: 0.6139 - val_loss: 1.2537 - val_acc: 0.5827\n",
            "Epoch 106/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 1.1282 - acc: 0.6029 - val_loss: 1.2520 - val_acc: 0.5951\n",
            "Epoch 107/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.1244 - acc: 0.6121 - val_loss: 1.2645 - val_acc: 0.5728\n",
            "Epoch 108/500\n",
            "1642/1642 [==============================] - 1s 315us/step - loss: 1.1236 - acc: 0.6114 - val_loss: 1.2475 - val_acc: 0.5926\n",
            "Epoch 109/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 1.1208 - acc: 0.6163 - val_loss: 1.2471 - val_acc: 0.5901\n",
            "Epoch 110/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 1.1179 - acc: 0.6218 - val_loss: 1.2528 - val_acc: 0.5778\n",
            "Epoch 111/500\n",
            "1642/1642 [==============================] - 0s 302us/step - loss: 1.1165 - acc: 0.6127 - val_loss: 1.2411 - val_acc: 0.5963\n",
            "Epoch 112/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.1136 - acc: 0.6236 - val_loss: 1.2434 - val_acc: 0.5877\n",
            "Epoch 113/500\n",
            "1642/1642 [==============================] - 0s 297us/step - loss: 1.1104 - acc: 0.6151 - val_loss: 1.2401 - val_acc: 0.6000\n",
            "Epoch 114/500\n",
            "1642/1642 [==============================] - 1s 305us/step - loss: 1.1073 - acc: 0.6236 - val_loss: 1.2428 - val_acc: 0.5827\n",
            "Epoch 115/500\n",
            "1642/1642 [==============================] - 0s 304us/step - loss: 1.1055 - acc: 0.6145 - val_loss: 1.2409 - val_acc: 0.5790\n",
            "Epoch 116/500\n",
            "1642/1642 [==============================] - 1s 316us/step - loss: 1.1037 - acc: 0.6261 - val_loss: 1.2354 - val_acc: 0.6025\n",
            "Epoch 117/500\n",
            "1642/1642 [==============================] - 0s 302us/step - loss: 1.1026 - acc: 0.6224 - val_loss: 1.2310 - val_acc: 0.6012\n",
            "Epoch 118/500\n",
            "1642/1642 [==============================] - 0s 302us/step - loss: 1.1003 - acc: 0.6285 - val_loss: 1.2283 - val_acc: 0.6086\n",
            "Epoch 119/500\n",
            "1642/1642 [==============================] - 0s 294us/step - loss: 1.0964 - acc: 0.6224 - val_loss: 1.2353 - val_acc: 0.5988\n",
            "Epoch 120/500\n",
            "1642/1642 [==============================] - 0s 299us/step - loss: 1.0911 - acc: 0.6261 - val_loss: 1.2387 - val_acc: 0.5963\n",
            "Epoch 121/500\n",
            "1642/1642 [==============================] - 0s 300us/step - loss: 1.0953 - acc: 0.6218 - val_loss: 1.2298 - val_acc: 0.5975\n",
            "Epoch 122/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 1.0898 - acc: 0.6163 - val_loss: 1.2246 - val_acc: 0.6025\n",
            "Epoch 123/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 1.0892 - acc: 0.6267 - val_loss: 1.2227 - val_acc: 0.6086\n",
            "Epoch 124/500\n",
            "1642/1642 [==============================] - 1s 307us/step - loss: 1.0868 - acc: 0.6315 - val_loss: 1.2221 - val_acc: 0.6049\n",
            "Epoch 125/500\n",
            "1642/1642 [==============================] - 0s 302us/step - loss: 1.0842 - acc: 0.6267 - val_loss: 1.2225 - val_acc: 0.6160\n",
            "Epoch 126/500\n",
            "1642/1642 [==============================] - 0s 302us/step - loss: 1.0820 - acc: 0.6291 - val_loss: 1.2192 - val_acc: 0.6012\n",
            "Epoch 127/500\n",
            "1642/1642 [==============================] - 0s 297us/step - loss: 1.0803 - acc: 0.6322 - val_loss: 1.2191 - val_acc: 0.5988\n",
            "Epoch 128/500\n",
            "1642/1642 [==============================] - 0s 301us/step - loss: 1.0789 - acc: 0.6230 - val_loss: 1.2185 - val_acc: 0.6099\n",
            "Epoch 129/500\n",
            "1642/1642 [==============================] - 0s 303us/step - loss: 1.0766 - acc: 0.6315 - val_loss: 1.2120 - val_acc: 0.6136\n",
            "Epoch 130/500\n",
            "1642/1642 [==============================] - 1s 315us/step - loss: 1.0716 - acc: 0.6364 - val_loss: 1.2182 - val_acc: 0.5988\n",
            "Epoch 131/500\n",
            "1642/1642 [==============================] - 1s 306us/step - loss: 1.0712 - acc: 0.6248 - val_loss: 1.2126 - val_acc: 0.6025\n",
            "Epoch 132/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 1.0697 - acc: 0.6358 - val_loss: 1.2141 - val_acc: 0.5988\n",
            "Epoch 133/500\n",
            "1642/1642 [==============================] - 0s 298us/step - loss: 1.0667 - acc: 0.6285 - val_loss: 1.2217 - val_acc: 0.5914\n",
            "Epoch 134/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 1.0667 - acc: 0.6315 - val_loss: 1.2104 - val_acc: 0.5988\n",
            "Epoch 135/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 1.0629 - acc: 0.6340 - val_loss: 1.2088 - val_acc: 0.6012\n",
            "Epoch 136/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 1.0636 - acc: 0.6382 - val_loss: 1.2056 - val_acc: 0.5988\n",
            "Epoch 137/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 1.0590 - acc: 0.6389 - val_loss: 1.2044 - val_acc: 0.6136\n",
            "Epoch 138/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 1.0578 - acc: 0.6364 - val_loss: 1.2033 - val_acc: 0.6111\n",
            "Epoch 139/500\n",
            "1642/1642 [==============================] - 1s 641us/step - loss: 1.0581 - acc: 0.6395 - val_loss: 1.1988 - val_acc: 0.6062\n",
            "Epoch 140/500\n",
            "1642/1642 [==============================] - 1s 355us/step - loss: 1.0557 - acc: 0.6309 - val_loss: 1.2007 - val_acc: 0.6037\n",
            "Epoch 141/500\n",
            "1642/1642 [==============================] - 1s 333us/step - loss: 1.0531 - acc: 0.6352 - val_loss: 1.1966 - val_acc: 0.6259\n",
            "Epoch 142/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 1.0497 - acc: 0.6456 - val_loss: 1.2021 - val_acc: 0.6062\n",
            "Epoch 143/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 1.0491 - acc: 0.6358 - val_loss: 1.2023 - val_acc: 0.6025\n",
            "Epoch 144/500\n",
            "1642/1642 [==============================] - 1s 337us/step - loss: 1.0464 - acc: 0.6322 - val_loss: 1.1979 - val_acc: 0.6062\n",
            "Epoch 145/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 1.0431 - acc: 0.6401 - val_loss: 1.2062 - val_acc: 0.5926\n",
            "Epoch 146/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 1.0459 - acc: 0.6322 - val_loss: 1.1922 - val_acc: 0.6148\n",
            "Epoch 147/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 1.0402 - acc: 0.6437 - val_loss: 1.2008 - val_acc: 0.6037\n",
            "Epoch 148/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 1.0392 - acc: 0.6437 - val_loss: 1.1925 - val_acc: 0.6123\n",
            "Epoch 149/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 1.0388 - acc: 0.6346 - val_loss: 1.1943 - val_acc: 0.6037\n",
            "Epoch 150/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 1.0353 - acc: 0.6419 - val_loss: 1.1903 - val_acc: 0.6136\n",
            "Epoch 151/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 1.0352 - acc: 0.6443 - val_loss: 1.1886 - val_acc: 0.6173\n",
            "Epoch 152/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 1.0340 - acc: 0.6431 - val_loss: 1.1875 - val_acc: 0.6210\n",
            "Epoch 153/500\n",
            "1642/1642 [==============================] - 1s 333us/step - loss: 1.0316 - acc: 0.6370 - val_loss: 1.1844 - val_acc: 0.6198\n",
            "Epoch 154/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 1.0302 - acc: 0.6492 - val_loss: 1.1862 - val_acc: 0.6272\n",
            "Epoch 155/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 1.0262 - acc: 0.6486 - val_loss: 1.1849 - val_acc: 0.6037\n",
            "Epoch 156/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 1.0242 - acc: 0.6468 - val_loss: 1.1850 - val_acc: 0.6111\n",
            "Epoch 157/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 1.0240 - acc: 0.6449 - val_loss: 1.1873 - val_acc: 0.6247\n",
            "Epoch 158/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 1.0231 - acc: 0.6535 - val_loss: 1.1787 - val_acc: 0.6160\n",
            "Epoch 159/500\n",
            "1642/1642 [==============================] - 1s 335us/step - loss: 1.0216 - acc: 0.6449 - val_loss: 1.1856 - val_acc: 0.6025\n",
            "Epoch 160/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 1.0210 - acc: 0.6498 - val_loss: 1.1791 - val_acc: 0.6049\n",
            "Epoch 161/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 1.0200 - acc: 0.6529 - val_loss: 1.1758 - val_acc: 0.6086\n",
            "Epoch 162/500\n",
            "1642/1642 [==============================] - 1s 354us/step - loss: 1.0173 - acc: 0.6529 - val_loss: 1.1763 - val_acc: 0.6160\n",
            "Epoch 163/500\n",
            "1642/1642 [==============================] - 1s 338us/step - loss: 1.0140 - acc: 0.6510 - val_loss: 1.1761 - val_acc: 0.6111\n",
            "Epoch 164/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 1.0152 - acc: 0.6516 - val_loss: 1.1758 - val_acc: 0.6062\n",
            "Epoch 165/500\n",
            "1642/1642 [==============================] - 1s 315us/step - loss: 1.0126 - acc: 0.6498 - val_loss: 1.1733 - val_acc: 0.6284\n",
            "Epoch 166/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 1.0099 - acc: 0.6516 - val_loss: 1.1753 - val_acc: 0.6049\n",
            "Epoch 167/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 1.0100 - acc: 0.6516 - val_loss: 1.1736 - val_acc: 0.6111\n",
            "Epoch 168/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 1.0069 - acc: 0.6492 - val_loss: 1.1723 - val_acc: 0.6136\n",
            "Epoch 169/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 1.0059 - acc: 0.6516 - val_loss: 1.1747 - val_acc: 0.6123\n",
            "Epoch 170/500\n",
            "1642/1642 [==============================] - 1s 337us/step - loss: 1.0044 - acc: 0.6492 - val_loss: 1.1710 - val_acc: 0.6123\n",
            "Epoch 171/500\n",
            "1642/1642 [==============================] - 1s 331us/step - loss: 1.0033 - acc: 0.6516 - val_loss: 1.1640 - val_acc: 0.6222\n",
            "Epoch 172/500\n",
            "1642/1642 [==============================] - 1s 338us/step - loss: 1.0012 - acc: 0.6553 - val_loss: 1.1643 - val_acc: 0.6210\n",
            "Epoch 173/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 1.0007 - acc: 0.6541 - val_loss: 1.1651 - val_acc: 0.6222\n",
            "Epoch 174/500\n",
            "1642/1642 [==============================] - 1s 336us/step - loss: 0.9991 - acc: 0.6486 - val_loss: 1.1644 - val_acc: 0.6086\n",
            "Epoch 175/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.9981 - acc: 0.6571 - val_loss: 1.1642 - val_acc: 0.6173\n",
            "Epoch 176/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.9923 - acc: 0.6632 - val_loss: 1.1646 - val_acc: 0.6296\n",
            "Epoch 177/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.9912 - acc: 0.6620 - val_loss: 1.1780 - val_acc: 0.6062\n",
            "Epoch 178/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.9942 - acc: 0.6596 - val_loss: 1.1649 - val_acc: 0.6259\n",
            "Epoch 179/500\n",
            "1642/1642 [==============================] - 1s 335us/step - loss: 0.9920 - acc: 0.6583 - val_loss: 1.1620 - val_acc: 0.6173\n",
            "Epoch 180/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.9884 - acc: 0.6596 - val_loss: 1.1659 - val_acc: 0.6123\n",
            "Epoch 181/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.9893 - acc: 0.6620 - val_loss: 1.1564 - val_acc: 0.6173\n",
            "Epoch 182/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.9869 - acc: 0.6583 - val_loss: 1.1558 - val_acc: 0.6111\n",
            "Epoch 183/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.9847 - acc: 0.6620 - val_loss: 1.1728 - val_acc: 0.6025\n",
            "Epoch 184/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.9851 - acc: 0.6577 - val_loss: 1.1603 - val_acc: 0.6136\n",
            "Epoch 185/500\n",
            "1642/1642 [==============================] - 1s 314us/step - loss: 0.9829 - acc: 0.6553 - val_loss: 1.1568 - val_acc: 0.6284\n",
            "Epoch 186/500\n",
            "1642/1642 [==============================] - 1s 334us/step - loss: 0.9819 - acc: 0.6620 - val_loss: 1.1521 - val_acc: 0.6222\n",
            "Epoch 187/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.9793 - acc: 0.6626 - val_loss: 1.1593 - val_acc: 0.6148\n",
            "Epoch 188/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.9804 - acc: 0.6547 - val_loss: 1.1491 - val_acc: 0.6272\n",
            "Epoch 189/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.9788 - acc: 0.6620 - val_loss: 1.1505 - val_acc: 0.6185\n",
            "Epoch 190/500\n",
            "1642/1642 [==============================] - 1s 336us/step - loss: 0.9766 - acc: 0.6620 - val_loss: 1.1508 - val_acc: 0.6160\n",
            "Epoch 191/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.9746 - acc: 0.6608 - val_loss: 1.1486 - val_acc: 0.6111\n",
            "Epoch 192/500\n",
            "1642/1642 [==============================] - 1s 307us/step - loss: 0.9751 - acc: 0.6644 - val_loss: 1.1473 - val_acc: 0.6247\n",
            "Epoch 193/500\n",
            "1642/1642 [==============================] - 1s 305us/step - loss: 0.9729 - acc: 0.6583 - val_loss: 1.1476 - val_acc: 0.6259\n",
            "Epoch 194/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.9715 - acc: 0.6663 - val_loss: 1.1448 - val_acc: 0.6247\n",
            "Epoch 195/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.9714 - acc: 0.6675 - val_loss: 1.1454 - val_acc: 0.6247\n",
            "Epoch 196/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.9658 - acc: 0.6669 - val_loss: 1.1504 - val_acc: 0.6111\n",
            "Epoch 197/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.9685 - acc: 0.6650 - val_loss: 1.1432 - val_acc: 0.6284\n",
            "Epoch 198/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.9659 - acc: 0.6632 - val_loss: 1.1444 - val_acc: 0.6210\n",
            "Epoch 199/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.9659 - acc: 0.6620 - val_loss: 1.1404 - val_acc: 0.6235\n",
            "Epoch 200/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.9620 - acc: 0.6699 - val_loss: 1.1540 - val_acc: 0.6185\n",
            "Epoch 201/500\n",
            "1642/1642 [==============================] - 1s 316us/step - loss: 0.9622 - acc: 0.6632 - val_loss: 1.1476 - val_acc: 0.6210\n",
            "Epoch 202/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.9578 - acc: 0.6778 - val_loss: 1.1424 - val_acc: 0.6235\n",
            "Epoch 203/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.9589 - acc: 0.6717 - val_loss: 1.1396 - val_acc: 0.6160\n",
            "Epoch 204/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.9581 - acc: 0.6711 - val_loss: 1.1439 - val_acc: 0.6173\n",
            "Epoch 205/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.9578 - acc: 0.6699 - val_loss: 1.1366 - val_acc: 0.6259\n",
            "Epoch 206/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.9552 - acc: 0.6724 - val_loss: 1.1394 - val_acc: 0.6296\n",
            "Epoch 207/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.9550 - acc: 0.6614 - val_loss: 1.1388 - val_acc: 0.6222\n",
            "Epoch 208/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.9525 - acc: 0.6657 - val_loss: 1.1429 - val_acc: 0.6210\n",
            "Epoch 209/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.9514 - acc: 0.6675 - val_loss: 1.1425 - val_acc: 0.6222\n",
            "Epoch 210/500\n",
            "1642/1642 [==============================] - 1s 334us/step - loss: 0.9508 - acc: 0.6760 - val_loss: 1.1414 - val_acc: 0.6198\n",
            "Epoch 211/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.9500 - acc: 0.6717 - val_loss: 1.1328 - val_acc: 0.6284\n",
            "Epoch 212/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 0.9501 - acc: 0.6675 - val_loss: 1.1310 - val_acc: 0.6284\n",
            "Epoch 213/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.9462 - acc: 0.6760 - val_loss: 1.1308 - val_acc: 0.6210\n",
            "Epoch 214/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.9457 - acc: 0.6687 - val_loss: 1.1329 - val_acc: 0.6296\n",
            "Epoch 215/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.9452 - acc: 0.6711 - val_loss: 1.1324 - val_acc: 0.6198\n",
            "Epoch 216/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.9429 - acc: 0.6736 - val_loss: 1.1293 - val_acc: 0.6309\n",
            "Epoch 217/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.9414 - acc: 0.6736 - val_loss: 1.1310 - val_acc: 0.6222\n",
            "Epoch 218/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.9392 - acc: 0.6772 - val_loss: 1.1309 - val_acc: 0.6284\n",
            "Epoch 219/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.9400 - acc: 0.6790 - val_loss: 1.1278 - val_acc: 0.6296\n",
            "Epoch 220/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.9379 - acc: 0.6790 - val_loss: 1.1333 - val_acc: 0.6259\n",
            "Epoch 221/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.9377 - acc: 0.6693 - val_loss: 1.1304 - val_acc: 0.6198\n",
            "Epoch 222/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.9352 - acc: 0.6815 - val_loss: 1.1289 - val_acc: 0.6222\n",
            "Epoch 223/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.9349 - acc: 0.6766 - val_loss: 1.1314 - val_acc: 0.6284\n",
            "Epoch 224/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.9333 - acc: 0.6778 - val_loss: 1.1345 - val_acc: 0.6123\n",
            "Epoch 225/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.9324 - acc: 0.6790 - val_loss: 1.1312 - val_acc: 0.6383\n",
            "Epoch 226/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.9339 - acc: 0.6809 - val_loss: 1.1239 - val_acc: 0.6284\n",
            "Epoch 227/500\n",
            "1642/1642 [==============================] - 1s 335us/step - loss: 0.9305 - acc: 0.6717 - val_loss: 1.1254 - val_acc: 0.6198\n",
            "Epoch 228/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.9292 - acc: 0.6827 - val_loss: 1.1290 - val_acc: 0.6198\n",
            "Epoch 229/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.9306 - acc: 0.6748 - val_loss: 1.1245 - val_acc: 0.6235\n",
            "Epoch 230/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.9273 - acc: 0.6760 - val_loss: 1.1260 - val_acc: 0.6235\n",
            "Epoch 231/500\n",
            "1642/1642 [==============================] - 1s 313us/step - loss: 0.9284 - acc: 0.6797 - val_loss: 1.1197 - val_acc: 0.6284\n",
            "Epoch 232/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.9237 - acc: 0.6748 - val_loss: 1.1267 - val_acc: 0.6321\n",
            "Epoch 233/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.9256 - acc: 0.6778 - val_loss: 1.1192 - val_acc: 0.6309\n",
            "Epoch 234/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.9242 - acc: 0.6784 - val_loss: 1.1210 - val_acc: 0.6321\n",
            "Epoch 235/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.9229 - acc: 0.6803 - val_loss: 1.1242 - val_acc: 0.6296\n",
            "Epoch 236/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.9214 - acc: 0.6748 - val_loss: 1.1204 - val_acc: 0.6222\n",
            "Epoch 237/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.9202 - acc: 0.6797 - val_loss: 1.1191 - val_acc: 0.6235\n",
            "Epoch 238/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.9190 - acc: 0.6784 - val_loss: 1.1168 - val_acc: 0.6333\n",
            "Epoch 239/500\n",
            "1642/1642 [==============================] - 1s 336us/step - loss: 0.9180 - acc: 0.6851 - val_loss: 1.1188 - val_acc: 0.6259\n",
            "Epoch 240/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.9143 - acc: 0.6967 - val_loss: 1.1268 - val_acc: 0.6247\n",
            "Epoch 241/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.9164 - acc: 0.6784 - val_loss: 1.1198 - val_acc: 0.6395\n",
            "Epoch 242/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.9162 - acc: 0.6809 - val_loss: 1.1188 - val_acc: 0.6247\n",
            "Epoch 243/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.9146 - acc: 0.6821 - val_loss: 1.1150 - val_acc: 0.6296\n",
            "Epoch 244/500\n",
            "1642/1642 [==============================] - 1s 334us/step - loss: 0.9109 - acc: 0.6894 - val_loss: 1.1124 - val_acc: 0.6284\n",
            "Epoch 245/500\n",
            "1642/1642 [==============================] - 1s 339us/step - loss: 0.9119 - acc: 0.6784 - val_loss: 1.1089 - val_acc: 0.6309\n",
            "Epoch 246/500\n",
            "1642/1642 [==============================] - 1s 331us/step - loss: 0.9113 - acc: 0.6918 - val_loss: 1.1107 - val_acc: 0.6333\n",
            "Epoch 247/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.9098 - acc: 0.6857 - val_loss: 1.1163 - val_acc: 0.6321\n",
            "Epoch 248/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.9099 - acc: 0.6857 - val_loss: 1.1102 - val_acc: 0.6321\n",
            "Epoch 249/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.9073 - acc: 0.6833 - val_loss: 1.1083 - val_acc: 0.6370\n",
            "Epoch 250/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.9045 - acc: 0.6864 - val_loss: 1.1114 - val_acc: 0.6284\n",
            "Epoch 251/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.9056 - acc: 0.6870 - val_loss: 1.1099 - val_acc: 0.6235\n",
            "Epoch 252/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.9043 - acc: 0.6803 - val_loss: 1.1063 - val_acc: 0.6333\n",
            "Epoch 253/500\n",
            "1642/1642 [==============================] - 1s 337us/step - loss: 0.9036 - acc: 0.6894 - val_loss: 1.1117 - val_acc: 0.6358\n",
            "Epoch 254/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.9029 - acc: 0.6857 - val_loss: 1.1065 - val_acc: 0.6383\n",
            "Epoch 255/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.9016 - acc: 0.6906 - val_loss: 1.1070 - val_acc: 0.6358\n",
            "Epoch 256/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 0.9007 - acc: 0.6803 - val_loss: 1.1110 - val_acc: 0.6272\n",
            "Epoch 257/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8999 - acc: 0.6857 - val_loss: 1.1061 - val_acc: 0.6321\n",
            "Epoch 258/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8981 - acc: 0.6912 - val_loss: 1.1103 - val_acc: 0.6296\n",
            "Epoch 259/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.8991 - acc: 0.6851 - val_loss: 1.1055 - val_acc: 0.6346\n",
            "Epoch 260/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.8957 - acc: 0.6821 - val_loss: 1.1079 - val_acc: 0.6395\n",
            "Epoch 261/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8950 - acc: 0.6839 - val_loss: 1.1062 - val_acc: 0.6296\n",
            "Epoch 262/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8930 - acc: 0.6943 - val_loss: 1.1090 - val_acc: 0.6222\n",
            "Epoch 263/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.8937 - acc: 0.6870 - val_loss: 1.1085 - val_acc: 0.6284\n",
            "Epoch 264/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8901 - acc: 0.6888 - val_loss: 1.1087 - val_acc: 0.6346\n",
            "Epoch 265/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.8907 - acc: 0.6833 - val_loss: 1.1032 - val_acc: 0.6346\n",
            "Epoch 266/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8911 - acc: 0.6876 - val_loss: 1.1020 - val_acc: 0.6395\n",
            "Epoch 267/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8897 - acc: 0.6894 - val_loss: 1.0998 - val_acc: 0.6309\n",
            "Epoch 268/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.8886 - acc: 0.6924 - val_loss: 1.1024 - val_acc: 0.6321\n",
            "Epoch 269/500\n",
            "1642/1642 [==============================] - 1s 310us/step - loss: 0.8878 - acc: 0.6912 - val_loss: 1.1017 - val_acc: 0.6296\n",
            "Epoch 270/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.8854 - acc: 0.6888 - val_loss: 1.1028 - val_acc: 0.6210\n",
            "Epoch 271/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.8865 - acc: 0.6931 - val_loss: 1.0990 - val_acc: 0.6358\n",
            "Epoch 272/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.8852 - acc: 0.6943 - val_loss: 1.0981 - val_acc: 0.6370\n",
            "Epoch 273/500\n",
            "1642/1642 [==============================] - 0s 305us/step - loss: 0.8840 - acc: 0.6924 - val_loss: 1.0967 - val_acc: 0.6346\n",
            "Epoch 274/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 0.8828 - acc: 0.6991 - val_loss: 1.1088 - val_acc: 0.6309\n",
            "Epoch 275/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.8826 - acc: 0.6918 - val_loss: 1.0957 - val_acc: 0.6321\n",
            "Epoch 276/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.8802 - acc: 0.6967 - val_loss: 1.1042 - val_acc: 0.6185\n",
            "Epoch 277/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8787 - acc: 0.6906 - val_loss: 1.1036 - val_acc: 0.6210\n",
            "Epoch 278/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8797 - acc: 0.6937 - val_loss: 1.0994 - val_acc: 0.6173\n",
            "Epoch 279/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8785 - acc: 0.6985 - val_loss: 1.0995 - val_acc: 0.6346\n",
            "Epoch 280/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.8770 - acc: 0.6985 - val_loss: 1.0958 - val_acc: 0.6383\n",
            "Epoch 281/500\n",
            "1642/1642 [==============================] - 1s 316us/step - loss: 0.8756 - acc: 0.6967 - val_loss: 1.1031 - val_acc: 0.6321\n",
            "Epoch 282/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8760 - acc: 0.6931 - val_loss: 1.0948 - val_acc: 0.6370\n",
            "Epoch 283/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8751 - acc: 0.6979 - val_loss: 1.0968 - val_acc: 0.6395\n",
            "Epoch 284/500\n",
            "1642/1642 [==============================] - 1s 333us/step - loss: 0.8745 - acc: 0.6943 - val_loss: 1.0954 - val_acc: 0.6370\n",
            "Epoch 285/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.8734 - acc: 0.6991 - val_loss: 1.0918 - val_acc: 0.6420\n",
            "Epoch 286/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8693 - acc: 0.6991 - val_loss: 1.0945 - val_acc: 0.6370\n",
            "Epoch 287/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.8717 - acc: 0.6991 - val_loss: 1.0920 - val_acc: 0.6370\n",
            "Epoch 288/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.8688 - acc: 0.7028 - val_loss: 1.0975 - val_acc: 0.6407\n",
            "Epoch 289/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8696 - acc: 0.6985 - val_loss: 1.0939 - val_acc: 0.6370\n",
            "Epoch 290/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8687 - acc: 0.6894 - val_loss: 1.0974 - val_acc: 0.6321\n",
            "Epoch 291/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.8665 - acc: 0.6998 - val_loss: 1.0928 - val_acc: 0.6358\n",
            "Epoch 292/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8673 - acc: 0.6991 - val_loss: 1.0935 - val_acc: 0.6296\n",
            "Epoch 293/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8663 - acc: 0.6931 - val_loss: 1.0899 - val_acc: 0.6383\n",
            "Epoch 294/500\n",
            "1642/1642 [==============================] - 1s 305us/step - loss: 0.8653 - acc: 0.6949 - val_loss: 1.0907 - val_acc: 0.6383\n",
            "Epoch 295/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8625 - acc: 0.6998 - val_loss: 1.0934 - val_acc: 0.6395\n",
            "Epoch 296/500\n",
            "1642/1642 [==============================] - 0s 304us/step - loss: 0.8644 - acc: 0.6961 - val_loss: 1.0912 - val_acc: 0.6370\n",
            "Epoch 297/500\n",
            "1642/1642 [==============================] - 1s 306us/step - loss: 0.8627 - acc: 0.7028 - val_loss: 1.0934 - val_acc: 0.6321\n",
            "Epoch 298/500\n",
            "1642/1642 [==============================] - 0s 301us/step - loss: 0.8638 - acc: 0.6949 - val_loss: 1.0898 - val_acc: 0.6457\n",
            "Epoch 299/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8603 - acc: 0.7022 - val_loss: 1.0899 - val_acc: 0.6481\n",
            "Epoch 300/500\n",
            "1642/1642 [==============================] - 1s 308us/step - loss: 0.8588 - acc: 0.7040 - val_loss: 1.0906 - val_acc: 0.6259\n",
            "Epoch 301/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8581 - acc: 0.6985 - val_loss: 1.0916 - val_acc: 0.6321\n",
            "Epoch 302/500\n",
            "1642/1642 [==============================] - 1s 307us/step - loss: 0.8578 - acc: 0.7058 - val_loss: 1.0869 - val_acc: 0.6395\n",
            "Epoch 303/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.8577 - acc: 0.6998 - val_loss: 1.0892 - val_acc: 0.6272\n",
            "Epoch 304/500\n",
            "1642/1642 [==============================] - 1s 306us/step - loss: 0.8568 - acc: 0.6943 - val_loss: 1.0847 - val_acc: 0.6407\n",
            "Epoch 305/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8546 - acc: 0.7077 - val_loss: 1.0894 - val_acc: 0.6420\n",
            "Epoch 306/500\n",
            "1642/1642 [==============================] - 1s 313us/step - loss: 0.8538 - acc: 0.7077 - val_loss: 1.0844 - val_acc: 0.6420\n",
            "Epoch 307/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.8557 - acc: 0.7010 - val_loss: 1.0817 - val_acc: 0.6432\n",
            "Epoch 308/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8527 - acc: 0.7010 - val_loss: 1.0905 - val_acc: 0.6309\n",
            "Epoch 309/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.8538 - acc: 0.7004 - val_loss: 1.0859 - val_acc: 0.6457\n",
            "Epoch 310/500\n",
            "1642/1642 [==============================] - 1s 312us/step - loss: 0.8507 - acc: 0.6998 - val_loss: 1.0821 - val_acc: 0.6383\n",
            "Epoch 311/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 0.8488 - acc: 0.7046 - val_loss: 1.0863 - val_acc: 0.6333\n",
            "Epoch 312/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 0.8512 - acc: 0.6991 - val_loss: 1.0821 - val_acc: 0.6407\n",
            "Epoch 313/500\n",
            "1642/1642 [==============================] - 1s 308us/step - loss: 0.8497 - acc: 0.7004 - val_loss: 1.0829 - val_acc: 0.6407\n",
            "Epoch 314/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.8494 - acc: 0.7071 - val_loss: 1.0807 - val_acc: 0.6407\n",
            "Epoch 315/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 0.8465 - acc: 0.7022 - val_loss: 1.0854 - val_acc: 0.6321\n",
            "Epoch 316/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8444 - acc: 0.7028 - val_loss: 1.0877 - val_acc: 0.6321\n",
            "Epoch 317/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8456 - acc: 0.7016 - val_loss: 1.0802 - val_acc: 0.6494\n",
            "Epoch 318/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8448 - acc: 0.7089 - val_loss: 1.0798 - val_acc: 0.6432\n",
            "Epoch 319/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.8450 - acc: 0.7089 - val_loss: 1.0801 - val_acc: 0.6481\n",
            "Epoch 320/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8444 - acc: 0.7156 - val_loss: 1.0779 - val_acc: 0.6457\n",
            "Epoch 321/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8414 - acc: 0.6998 - val_loss: 1.0810 - val_acc: 0.6383\n",
            "Epoch 322/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.8421 - acc: 0.7077 - val_loss: 1.0767 - val_acc: 0.6432\n",
            "Epoch 323/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8405 - acc: 0.7040 - val_loss: 1.0831 - val_acc: 0.6407\n",
            "Epoch 324/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.8396 - acc: 0.7174 - val_loss: 1.0806 - val_acc: 0.6370\n",
            "Epoch 325/500\n",
            "1642/1642 [==============================] - 1s 331us/step - loss: 0.8385 - acc: 0.7058 - val_loss: 1.0775 - val_acc: 0.6395\n",
            "Epoch 326/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8385 - acc: 0.7004 - val_loss: 1.0752 - val_acc: 0.6420\n",
            "Epoch 327/500\n",
            "1642/1642 [==============================] - 1s 315us/step - loss: 0.8378 - acc: 0.7052 - val_loss: 1.0772 - val_acc: 0.6370\n",
            "Epoch 328/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.8380 - acc: 0.7119 - val_loss: 1.0766 - val_acc: 0.6420\n",
            "Epoch 329/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.8366 - acc: 0.7046 - val_loss: 1.0744 - val_acc: 0.6420\n",
            "Epoch 330/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8354 - acc: 0.7113 - val_loss: 1.0787 - val_acc: 0.6309\n",
            "Epoch 331/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.8349 - acc: 0.7077 - val_loss: 1.0780 - val_acc: 0.6444\n",
            "Epoch 332/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8357 - acc: 0.7089 - val_loss: 1.0726 - val_acc: 0.6457\n",
            "Epoch 333/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.8324 - acc: 0.7119 - val_loss: 1.0761 - val_acc: 0.6296\n",
            "Epoch 334/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.8320 - acc: 0.7071 - val_loss: 1.0787 - val_acc: 0.6395\n",
            "Epoch 335/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.8308 - acc: 0.6998 - val_loss: 1.0771 - val_acc: 0.6395\n",
            "Epoch 336/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8304 - acc: 0.7132 - val_loss: 1.0753 - val_acc: 0.6309\n",
            "Epoch 337/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.8292 - acc: 0.7125 - val_loss: 1.0772 - val_acc: 0.6469\n",
            "Epoch 338/500\n",
            "1642/1642 [==============================] - 0s 302us/step - loss: 0.8284 - acc: 0.7095 - val_loss: 1.0730 - val_acc: 0.6444\n",
            "Epoch 339/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.8277 - acc: 0.7083 - val_loss: 1.0857 - val_acc: 0.6272\n",
            "Epoch 340/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.8272 - acc: 0.7046 - val_loss: 1.0787 - val_acc: 0.6457\n",
            "Epoch 341/500\n",
            "1642/1642 [==============================] - 1s 331us/step - loss: 0.8271 - acc: 0.7119 - val_loss: 1.0784 - val_acc: 0.6420\n",
            "Epoch 342/500\n",
            "1642/1642 [==============================] - 1s 333us/step - loss: 0.8271 - acc: 0.7119 - val_loss: 1.0745 - val_acc: 0.6296\n",
            "Epoch 343/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.8266 - acc: 0.7107 - val_loss: 1.0700 - val_acc: 0.6407\n",
            "Epoch 344/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8243 - acc: 0.7101 - val_loss: 1.0715 - val_acc: 0.6370\n",
            "Epoch 345/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.8240 - acc: 0.7077 - val_loss: 1.0726 - val_acc: 0.6383\n",
            "Epoch 346/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.8232 - acc: 0.7132 - val_loss: 1.0751 - val_acc: 0.6333\n",
            "Epoch 347/500\n",
            "1642/1642 [==============================] - 1s 331us/step - loss: 0.8218 - acc: 0.7180 - val_loss: 1.0730 - val_acc: 0.6407\n",
            "Epoch 348/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8212 - acc: 0.7162 - val_loss: 1.0715 - val_acc: 0.6383\n",
            "Epoch 349/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.8197 - acc: 0.7132 - val_loss: 1.0709 - val_acc: 0.6407\n",
            "Epoch 350/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.8211 - acc: 0.7180 - val_loss: 1.0712 - val_acc: 0.6481\n",
            "Epoch 351/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.8178 - acc: 0.7174 - val_loss: 1.0700 - val_acc: 0.6358\n",
            "Epoch 352/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.8184 - acc: 0.7150 - val_loss: 1.0726 - val_acc: 0.6481\n",
            "Epoch 353/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.8184 - acc: 0.7083 - val_loss: 1.0720 - val_acc: 0.6494\n",
            "Epoch 354/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.8181 - acc: 0.7205 - val_loss: 1.0674 - val_acc: 0.6432\n",
            "Epoch 355/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.8161 - acc: 0.7162 - val_loss: 1.0702 - val_acc: 0.6346\n",
            "Epoch 356/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.8165 - acc: 0.7199 - val_loss: 1.0725 - val_acc: 0.6469\n",
            "Epoch 357/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.8158 - acc: 0.7095 - val_loss: 1.0659 - val_acc: 0.6519\n",
            "Epoch 358/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8150 - acc: 0.7132 - val_loss: 1.0683 - val_acc: 0.6420\n",
            "Epoch 359/500\n",
            "1642/1642 [==============================] - 1s 337us/step - loss: 0.8143 - acc: 0.7132 - val_loss: 1.0654 - val_acc: 0.6444\n",
            "Epoch 360/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.8138 - acc: 0.7144 - val_loss: 1.0677 - val_acc: 0.6494\n",
            "Epoch 361/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8129 - acc: 0.7113 - val_loss: 1.0671 - val_acc: 0.6506\n",
            "Epoch 362/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.8124 - acc: 0.7211 - val_loss: 1.0689 - val_acc: 0.6383\n",
            "Epoch 363/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8096 - acc: 0.7174 - val_loss: 1.0681 - val_acc: 0.6457\n",
            "Epoch 364/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8110 - acc: 0.7107 - val_loss: 1.0665 - val_acc: 0.6444\n",
            "Epoch 365/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.8096 - acc: 0.7180 - val_loss: 1.0666 - val_acc: 0.6481\n",
            "Epoch 366/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8093 - acc: 0.7101 - val_loss: 1.0654 - val_acc: 0.6494\n",
            "Epoch 367/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.8090 - acc: 0.7138 - val_loss: 1.0678 - val_acc: 0.6506\n",
            "Epoch 368/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.8077 - acc: 0.7125 - val_loss: 1.0664 - val_acc: 0.6444\n",
            "Epoch 369/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8063 - acc: 0.7192 - val_loss: 1.0702 - val_acc: 0.6358\n",
            "Epoch 370/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8068 - acc: 0.7217 - val_loss: 1.0654 - val_acc: 0.6506\n",
            "Epoch 371/500\n",
            "1642/1642 [==============================] - 1s 333us/step - loss: 0.8061 - acc: 0.7174 - val_loss: 1.0652 - val_acc: 0.6457\n",
            "Epoch 372/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.8044 - acc: 0.7247 - val_loss: 1.0633 - val_acc: 0.6519\n",
            "Epoch 373/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.8056 - acc: 0.7174 - val_loss: 1.0653 - val_acc: 0.6444\n",
            "Epoch 374/500\n",
            "1642/1642 [==============================] - 1s 341us/step - loss: 0.8030 - acc: 0.7180 - val_loss: 1.0648 - val_acc: 0.6432\n",
            "Epoch 375/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.8026 - acc: 0.7199 - val_loss: 1.0646 - val_acc: 0.6494\n",
            "Epoch 376/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.8018 - acc: 0.7138 - val_loss: 1.0670 - val_acc: 0.6469\n",
            "Epoch 377/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.8022 - acc: 0.7247 - val_loss: 1.0605 - val_acc: 0.6395\n",
            "Epoch 378/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.7991 - acc: 0.7223 - val_loss: 1.0642 - val_acc: 0.6494\n",
            "Epoch 379/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.8007 - acc: 0.7192 - val_loss: 1.0631 - val_acc: 0.6519\n",
            "Epoch 380/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7987 - acc: 0.7205 - val_loss: 1.0610 - val_acc: 0.6481\n",
            "Epoch 381/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.7986 - acc: 0.7223 - val_loss: 1.0621 - val_acc: 0.6358\n",
            "Epoch 382/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.7959 - acc: 0.7266 - val_loss: 1.0703 - val_acc: 0.6358\n",
            "Epoch 383/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.7970 - acc: 0.7284 - val_loss: 1.0728 - val_acc: 0.6296\n",
            "Epoch 384/500\n",
            "1642/1642 [==============================] - 1s 340us/step - loss: 0.7962 - acc: 0.7217 - val_loss: 1.0656 - val_acc: 0.6444\n",
            "Epoch 385/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.7952 - acc: 0.7217 - val_loss: 1.0637 - val_acc: 0.6457\n",
            "Epoch 386/500\n",
            "1642/1642 [==============================] - 1s 357us/step - loss: 0.7931 - acc: 0.7205 - val_loss: 1.0651 - val_acc: 0.6469\n",
            "Epoch 387/500\n",
            "1642/1642 [==============================] - 1s 394us/step - loss: 0.7927 - acc: 0.7284 - val_loss: 1.0594 - val_acc: 0.6494\n",
            "Epoch 388/500\n",
            "1642/1642 [==============================] - 1s 384us/step - loss: 0.7933 - acc: 0.7186 - val_loss: 1.0612 - val_acc: 0.6457\n",
            "Epoch 389/500\n",
            "1642/1642 [==============================] - 1s 392us/step - loss: 0.7928 - acc: 0.7205 - val_loss: 1.0648 - val_acc: 0.6494\n",
            "Epoch 390/500\n",
            "1642/1642 [==============================] - 1s 378us/step - loss: 0.7948 - acc: 0.7211 - val_loss: 1.0582 - val_acc: 0.6457\n",
            "Epoch 391/500\n",
            "1642/1642 [==============================] - 1s 378us/step - loss: 0.7894 - acc: 0.7223 - val_loss: 1.0669 - val_acc: 0.6420\n",
            "Epoch 392/500\n",
            "1642/1642 [==============================] - 1s 376us/step - loss: 0.7915 - acc: 0.7180 - val_loss: 1.0630 - val_acc: 0.6370\n",
            "Epoch 393/500\n",
            "1642/1642 [==============================] - 1s 385us/step - loss: 0.7889 - acc: 0.7308 - val_loss: 1.0606 - val_acc: 0.6531\n",
            "Epoch 394/500\n",
            "1642/1642 [==============================] - 1s 398us/step - loss: 0.7878 - acc: 0.7259 - val_loss: 1.0607 - val_acc: 0.6420\n",
            "Epoch 395/500\n",
            "1642/1642 [==============================] - 1s 357us/step - loss: 0.7881 - acc: 0.7247 - val_loss: 1.0573 - val_acc: 0.6420\n",
            "Epoch 396/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7900 - acc: 0.7241 - val_loss: 1.0587 - val_acc: 0.6444\n",
            "Epoch 397/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.7873 - acc: 0.7211 - val_loss: 1.0567 - val_acc: 0.6420\n",
            "Epoch 398/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.7857 - acc: 0.7247 - val_loss: 1.0668 - val_acc: 0.6346\n",
            "Epoch 399/500\n",
            "1642/1642 [==============================] - 1s 331us/step - loss: 0.7872 - acc: 0.7241 - val_loss: 1.0579 - val_acc: 0.6457\n",
            "Epoch 400/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.7852 - acc: 0.7308 - val_loss: 1.0586 - val_acc: 0.6370\n",
            "Epoch 401/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.7823 - acc: 0.7241 - val_loss: 1.0612 - val_acc: 0.6543\n",
            "Epoch 402/500\n",
            "1642/1642 [==============================] - 1s 337us/step - loss: 0.7855 - acc: 0.7253 - val_loss: 1.0554 - val_acc: 0.6420\n",
            "Epoch 403/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.7828 - acc: 0.7223 - val_loss: 1.0623 - val_acc: 0.6420\n",
            "Epoch 404/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.7829 - acc: 0.7272 - val_loss: 1.0585 - val_acc: 0.6469\n",
            "Epoch 405/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.7831 - acc: 0.7302 - val_loss: 1.0589 - val_acc: 0.6568\n",
            "Epoch 406/500\n",
            "1642/1642 [==============================] - 1s 343us/step - loss: 0.7811 - acc: 0.7314 - val_loss: 1.0570 - val_acc: 0.6556\n",
            "Epoch 407/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7806 - acc: 0.7278 - val_loss: 1.0588 - val_acc: 0.6432\n",
            "Epoch 408/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7820 - acc: 0.7253 - val_loss: 1.0550 - val_acc: 0.6457\n",
            "Epoch 409/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7806 - acc: 0.7320 - val_loss: 1.0558 - val_acc: 0.6556\n",
            "Epoch 410/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.7785 - acc: 0.7357 - val_loss: 1.0642 - val_acc: 0.6407\n",
            "Epoch 411/500\n",
            "1642/1642 [==============================] - 1s 316us/step - loss: 0.7771 - acc: 0.7296 - val_loss: 1.0578 - val_acc: 0.6407\n",
            "Epoch 412/500\n",
            "1642/1642 [==============================] - 1s 310us/step - loss: 0.7788 - acc: 0.7308 - val_loss: 1.0585 - val_acc: 0.6407\n",
            "Epoch 413/500\n",
            "1642/1642 [==============================] - 0s 304us/step - loss: 0.7778 - acc: 0.7320 - val_loss: 1.0537 - val_acc: 0.6506\n",
            "Epoch 414/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.7772 - acc: 0.7284 - val_loss: 1.0522 - val_acc: 0.6370\n",
            "Epoch 415/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.7758 - acc: 0.7284 - val_loss: 1.0562 - val_acc: 0.6519\n",
            "Epoch 416/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7755 - acc: 0.7302 - val_loss: 1.0551 - val_acc: 0.6531\n",
            "Epoch 417/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.7757 - acc: 0.7302 - val_loss: 1.0545 - val_acc: 0.6469\n",
            "Epoch 418/500\n",
            "1642/1642 [==============================] - 1s 315us/step - loss: 0.7747 - acc: 0.7259 - val_loss: 1.0512 - val_acc: 0.6420\n",
            "Epoch 419/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.7746 - acc: 0.7272 - val_loss: 1.0523 - val_acc: 0.6506\n",
            "Epoch 420/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7740 - acc: 0.7290 - val_loss: 1.0544 - val_acc: 0.6432\n",
            "Epoch 421/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.7746 - acc: 0.7296 - val_loss: 1.0526 - val_acc: 0.6481\n",
            "Epoch 422/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7718 - acc: 0.7351 - val_loss: 1.0543 - val_acc: 0.6481\n",
            "Epoch 423/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.7690 - acc: 0.7339 - val_loss: 1.0570 - val_acc: 0.6469\n",
            "Epoch 424/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 0.7687 - acc: 0.7302 - val_loss: 1.0632 - val_acc: 0.6321\n",
            "Epoch 425/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7707 - acc: 0.7351 - val_loss: 1.0529 - val_acc: 0.6395\n",
            "Epoch 426/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.7676 - acc: 0.7381 - val_loss: 1.0574 - val_acc: 0.6494\n",
            "Epoch 427/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.7684 - acc: 0.7363 - val_loss: 1.0544 - val_acc: 0.6568\n",
            "Epoch 428/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.7663 - acc: 0.7333 - val_loss: 1.0549 - val_acc: 0.6543\n",
            "Epoch 429/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7684 - acc: 0.7290 - val_loss: 1.0518 - val_acc: 0.6432\n",
            "Epoch 430/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.7665 - acc: 0.7357 - val_loss: 1.0550 - val_acc: 0.6420\n",
            "Epoch 431/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.7666 - acc: 0.7363 - val_loss: 1.0513 - val_acc: 0.6494\n",
            "Epoch 432/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.7652 - acc: 0.7302 - val_loss: 1.0535 - val_acc: 0.6494\n",
            "Epoch 433/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7655 - acc: 0.7345 - val_loss: 1.0627 - val_acc: 0.6296\n",
            "Epoch 434/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.7657 - acc: 0.7326 - val_loss: 1.0516 - val_acc: 0.6531\n",
            "Epoch 435/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7640 - acc: 0.7406 - val_loss: 1.0537 - val_acc: 0.6568\n",
            "Epoch 436/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.7633 - acc: 0.7296 - val_loss: 1.0518 - val_acc: 0.6506\n",
            "Epoch 437/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7629 - acc: 0.7363 - val_loss: 1.0527 - val_acc: 0.6370\n",
            "Epoch 438/500\n",
            "1642/1642 [==============================] - 1s 314us/step - loss: 0.7619 - acc: 0.7387 - val_loss: 1.0522 - val_acc: 0.6444\n",
            "Epoch 439/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.7619 - acc: 0.7381 - val_loss: 1.0505 - val_acc: 0.6432\n",
            "Epoch 440/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 0.7600 - acc: 0.7314 - val_loss: 1.0510 - val_acc: 0.6481\n",
            "Epoch 441/500\n",
            "1642/1642 [==============================] - 1s 315us/step - loss: 0.7601 - acc: 0.7308 - val_loss: 1.0490 - val_acc: 0.6519\n",
            "Epoch 442/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.7587 - acc: 0.7424 - val_loss: 1.0546 - val_acc: 0.6444\n",
            "Epoch 443/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.7602 - acc: 0.7387 - val_loss: 1.0481 - val_acc: 0.6444\n",
            "Epoch 444/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.7565 - acc: 0.7381 - val_loss: 1.0585 - val_acc: 0.6556\n",
            "Epoch 445/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.7567 - acc: 0.7393 - val_loss: 1.0510 - val_acc: 0.6444\n",
            "Epoch 446/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7577 - acc: 0.7375 - val_loss: 1.0508 - val_acc: 0.6407\n",
            "Epoch 447/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7560 - acc: 0.7345 - val_loss: 1.0500 - val_acc: 0.6519\n",
            "Epoch 448/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 0.7557 - acc: 0.7454 - val_loss: 1.0513 - val_acc: 0.6605\n",
            "Epoch 449/500\n",
            "1642/1642 [==============================] - 0s 298us/step - loss: 0.7528 - acc: 0.7479 - val_loss: 1.0544 - val_acc: 0.6407\n",
            "Epoch 450/500\n",
            "1642/1642 [==============================] - 1s 312us/step - loss: 0.7535 - acc: 0.7375 - val_loss: 1.0515 - val_acc: 0.6420\n",
            "Epoch 451/500\n",
            "1642/1642 [==============================] - 1s 331us/step - loss: 0.7545 - acc: 0.7400 - val_loss: 1.0493 - val_acc: 0.6481\n",
            "Epoch 452/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7541 - acc: 0.7406 - val_loss: 1.0475 - val_acc: 0.6432\n",
            "Epoch 453/500\n",
            "1642/1642 [==============================] - 1s 316us/step - loss: 0.7539 - acc: 0.7363 - val_loss: 1.0465 - val_acc: 0.6481\n",
            "Epoch 454/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.7525 - acc: 0.7436 - val_loss: 1.0463 - val_acc: 0.6506\n",
            "Epoch 455/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.7531 - acc: 0.7430 - val_loss: 1.0506 - val_acc: 0.6531\n",
            "Epoch 456/500\n",
            "1642/1642 [==============================] - 1s 311us/step - loss: 0.7519 - acc: 0.7393 - val_loss: 1.0513 - val_acc: 0.6506\n",
            "Epoch 457/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7520 - acc: 0.7400 - val_loss: 1.0476 - val_acc: 0.6481\n",
            "Epoch 458/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.7486 - acc: 0.7454 - val_loss: 1.0561 - val_acc: 0.6506\n",
            "Epoch 459/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7503 - acc: 0.7412 - val_loss: 1.0506 - val_acc: 0.6469\n",
            "Epoch 460/500\n",
            "1642/1642 [==============================] - 1s 318us/step - loss: 0.7473 - acc: 0.7430 - val_loss: 1.0443 - val_acc: 0.6370\n",
            "Epoch 461/500\n",
            "1642/1642 [==============================] - 1s 313us/step - loss: 0.7482 - acc: 0.7448 - val_loss: 1.0445 - val_acc: 0.6432\n",
            "Epoch 462/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.7465 - acc: 0.7375 - val_loss: 1.0483 - val_acc: 0.6395\n",
            "Epoch 463/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.7454 - acc: 0.7436 - val_loss: 1.0581 - val_acc: 0.6519\n",
            "Epoch 464/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.7473 - acc: 0.7479 - val_loss: 1.0455 - val_acc: 0.6506\n",
            "Epoch 465/500\n",
            "1642/1642 [==============================] - 1s 316us/step - loss: 0.7448 - acc: 0.7442 - val_loss: 1.0448 - val_acc: 0.6432\n",
            "Epoch 466/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.7453 - acc: 0.7430 - val_loss: 1.0475 - val_acc: 0.6506\n",
            "Epoch 467/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.7467 - acc: 0.7460 - val_loss: 1.0461 - val_acc: 0.6469\n",
            "Epoch 468/500\n",
            "1642/1642 [==============================] - 1s 307us/step - loss: 0.7453 - acc: 0.7393 - val_loss: 1.0446 - val_acc: 0.6444\n",
            "Epoch 469/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.7449 - acc: 0.7424 - val_loss: 1.0471 - val_acc: 0.6580\n",
            "Epoch 470/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.7432 - acc: 0.7485 - val_loss: 1.0499 - val_acc: 0.6556\n",
            "Epoch 471/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.7449 - acc: 0.7479 - val_loss: 1.0450 - val_acc: 0.6519\n",
            "Epoch 472/500\n",
            "1642/1642 [==============================] - 1s 332us/step - loss: 0.7415 - acc: 0.7479 - val_loss: 1.0441 - val_acc: 0.6407\n",
            "Epoch 473/500\n",
            "1642/1642 [==============================] - 1s 317us/step - loss: 0.7420 - acc: 0.7497 - val_loss: 1.0479 - val_acc: 0.6432\n",
            "Epoch 474/500\n",
            "1642/1642 [==============================] - 1s 331us/step - loss: 0.7404 - acc: 0.7436 - val_loss: 1.0479 - val_acc: 0.6407\n",
            "Epoch 475/500\n",
            "1642/1642 [==============================] - 1s 314us/step - loss: 0.7421 - acc: 0.7424 - val_loss: 1.0463 - val_acc: 0.6469\n",
            "Epoch 476/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.7392 - acc: 0.7497 - val_loss: 1.0457 - val_acc: 0.6568\n",
            "Epoch 477/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.7392 - acc: 0.7448 - val_loss: 1.0439 - val_acc: 0.6420\n",
            "Epoch 478/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.7372 - acc: 0.7430 - val_loss: 1.0513 - val_acc: 0.6494\n",
            "Epoch 479/500\n",
            "1642/1642 [==============================] - 1s 316us/step - loss: 0.7392 - acc: 0.7473 - val_loss: 1.0488 - val_acc: 0.6568\n",
            "Epoch 480/500\n",
            "1642/1642 [==============================] - 1s 319us/step - loss: 0.7366 - acc: 0.7424 - val_loss: 1.0504 - val_acc: 0.6580\n",
            "Epoch 481/500\n",
            "1642/1642 [==============================] - 1s 324us/step - loss: 0.7370 - acc: 0.7400 - val_loss: 1.0471 - val_acc: 0.6481\n",
            "Epoch 482/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.7358 - acc: 0.7442 - val_loss: 1.0445 - val_acc: 0.6543\n",
            "Epoch 483/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7371 - acc: 0.7424 - val_loss: 1.0472 - val_acc: 0.6531\n",
            "Epoch 484/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.7369 - acc: 0.7497 - val_loss: 1.0436 - val_acc: 0.6481\n",
            "Epoch 485/500\n",
            "1642/1642 [==============================] - 1s 323us/step - loss: 0.7342 - acc: 0.7497 - val_loss: 1.0420 - val_acc: 0.6444\n",
            "Epoch 486/500\n",
            "1642/1642 [==============================] - 1s 320us/step - loss: 0.7350 - acc: 0.7430 - val_loss: 1.0455 - val_acc: 0.6543\n",
            "Epoch 487/500\n",
            "1642/1642 [==============================] - 1s 322us/step - loss: 0.7344 - acc: 0.7479 - val_loss: 1.0428 - val_acc: 0.6481\n",
            "Epoch 488/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.7325 - acc: 0.7448 - val_loss: 1.0499 - val_acc: 0.6469\n",
            "Epoch 489/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.7337 - acc: 0.7418 - val_loss: 1.0409 - val_acc: 0.6457\n",
            "Epoch 490/500\n",
            "1642/1642 [==============================] - 1s 316us/step - loss: 0.7328 - acc: 0.7479 - val_loss: 1.0429 - val_acc: 0.6432\n",
            "Epoch 491/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.7306 - acc: 0.7479 - val_loss: 1.0464 - val_acc: 0.6481\n",
            "Epoch 492/500\n",
            "1642/1642 [==============================] - 1s 321us/step - loss: 0.7307 - acc: 0.7473 - val_loss: 1.0438 - val_acc: 0.6568\n",
            "Epoch 493/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7309 - acc: 0.7497 - val_loss: 1.0421 - val_acc: 0.6457\n",
            "Epoch 494/500\n",
            "1642/1642 [==============================] - 1s 315us/step - loss: 0.7304 - acc: 0.7497 - val_loss: 1.0405 - val_acc: 0.6469\n",
            "Epoch 495/500\n",
            "1642/1642 [==============================] - 1s 327us/step - loss: 0.7299 - acc: 0.7473 - val_loss: 1.0427 - val_acc: 0.6519\n",
            "Epoch 496/500\n",
            "1642/1642 [==============================] - 1s 325us/step - loss: 0.7272 - acc: 0.7454 - val_loss: 1.0451 - val_acc: 0.6333\n",
            "Epoch 497/500\n",
            "1642/1642 [==============================] - 1s 326us/step - loss: 0.7278 - acc: 0.7521 - val_loss: 1.0434 - val_acc: 0.6481\n",
            "Epoch 498/500\n",
            "1642/1642 [==============================] - 1s 328us/step - loss: 0.7271 - acc: 0.7460 - val_loss: 1.0467 - val_acc: 0.6494\n",
            "Epoch 499/500\n",
            "1642/1642 [==============================] - 1s 330us/step - loss: 0.7269 - acc: 0.7491 - val_loss: 1.0415 - val_acc: 0.6543\n",
            "Epoch 500/500\n",
            "1642/1642 [==============================] - 1s 329us/step - loss: 0.7259 - acc: 0.7503 - val_loss: 1.0414 - val_acc: 0.6531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mFytY6LDzgJ0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's plot the loss:"
      ]
    },
    {
      "metadata": {
        "id": "TFz4ClZov9gZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "c979e2dd-fb06-4f95-facd-d56471c9de7e"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2698f893c8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Vf1W7LgP2DA5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "And now let's plot the accuracy:"
      ]
    },
    {
      "metadata": {
        "id": "8yyFBt7ASPUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "10fb68a1-dfa5-401e-e053-5749d9eb685c"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(cnnhistory.history['acc'])\n",
        "plt.plot(cnnhistory.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f269913b128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "x_ySPOyHxkZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Observations\n",
        "\n",
        "As you can see from the graph above, after 150 epochs the model starts to overfit: the training set accuracy increases while the test set accuracy remains more or less the same.\n",
        "\n",
        "On the other hand, the loss obtained is quite good.\n",
        "\n",
        "If we add more epochs to the network, the result will be a great increment of the accuracy on the training set without a significant improvement on the test set.\n",
        "\n",
        "Overfitting means that the model tends to be accurate only with the data we are using for the training.\n",
        "\n",
        "Now we can save our model:"
      ]
    },
    {
      "metadata": {
        "id": "f5kRmoD-sdHj",
        "colab_type": "code",
        "outputId": "fb607fbd-377e-47b0-b3c7-eb4ea313b028",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model_name = 'Emotion_Voice_Detection_Model.h5'\n",
        "save_dir = '/content/drive/My Drive/Ravdess_model'\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/drive/My Drive/Ravdess_model/Emotion_Voice_Detection_Model.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MNUiznKNwUtJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Thanks for reading: to be continued..."
      ]
    }
  ]
}
